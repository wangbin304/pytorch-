
1. Tensor 类型
## tensor 类型

import torch as t

# t.set_default_tensor_type("torch.HalfTensor")
# a=t.Tensor(2,3)
a=t.ones(2,3)
print(a,a.dtype)
t.set_default_tensor_type("torch.HalfTensor")
a=t.ones(2,3)
print(a,a.dtype)
t.set_default_tensor_type("torch.DoubleTensor")
a=t.ones(2,3)
print(a,a.dtype)

#  等价的方式
a=a.float()
print(a,a.dtype)
a=a.half()
print(a,a.dtype)
a=a.double()
print(a,a.dtype)
# print(a,a.dtype,a.shape)

#  等价方式
b=a.half()
print("b=",b)
d=a.double()
d=t.Tensor(2,3)
print("d=",d,d.dtype)
# float64 -> float16   数据太大或者太小  超范围越界  显示出错
e=d.type_as(b)
print("e=",e,e.dtype)


# 恢复之前的默认设置
t.set_default_tensor_type("torch.FloatTensor")
print("e=",e,e.dtype)

a=t.Tensor(2,3)
print(a,a.dtype)






/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[1., 1., 1.],
        [1., 1., 1.]]) torch.float32
tensor([[1., 1., 1.],
        [1., 1., 1.]]) torch.float16
tensor([[1., 1., 1.],
        [1., 1., 1.]]) torch.float64
tensor([[1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float32) torch.float32
tensor([[1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float16) torch.float16
tensor([[1., 1., 1.],
        [1., 1., 1.]]) torch.float64
b= tensor([[1., 1., 1.],
        [1., 1., 1.]], dtype=torch.float16)
d= tensor([[5.2519e+170, 2.6452e+185, 3.9469e+252],
        [4.9343e+257, 4.6853e-310, 4.6853e-310]]) torch.float64
e= tensor([[inf, inf, inf],
        [inf, 0., 0.]], dtype=torch.float16) torch.float16
e= tensor([[inf, inf, inf],
        [inf, 0., 0.]], dtype=torch.float16) torch.float16
tensor([[-1.3205e-09,  4.5621e-41, -1.3205e-09],
        [ 4.5621e-41,  0.0000e+00,  0.0000e+00]]) torch.float32

Process finished with exit code 0





2. 逐元素操作

注：此类操作输入输出形状一致


import torch as t

#  小数才可以调用cos
a=t.arange(0,8).view(2,4).float()
print(a)
print(t.cos(a))
#a=a.int()
print(a%3)

print(a**2)

print(t.clamp(a,min=3))

print(t.clamp(a,min=3,max=5))


/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[0., 1., 2., 3.],
        [4., 5., 6., 7.]])
tensor([[ 1.0000,  0.5403, -0.4161, -0.9900],
        [-0.6536,  0.2837,  0.9602,  0.7539]])
tensor([[0., 1., 2., 0.],
        [1., 2., 0., 1.]])
tensor([[ 0.,  1.,  4.,  9.],
        [16., 25., 36., 49.]])
tensor([[3., 3., 3., 3.],
        [4., 5., 6., 7.]])
tensor([[3., 3., 3., 3.],
        [4., 5., 5., 5.]])

Process finished with exit code 0



3. 归并操作

注：输出形状小于输入形状

import torch as t

b=t.ones(2,3)
print(b)

print(b.sum(dim=0,keepdim=True),b.sum(dim=0,keepdim=True).shape)

print(b.sum(dim=0,keepdim=False),b.sum(dim=0,keepdim=False).shape)

print(b.sum(dim=1))

a=t.arange(0,6).view(2,3)
print(a)
print(a.cumsum(dim=1))



/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[1., 1., 1.],
        [1., 1., 1.]])
tensor([[2., 2., 2.]]) torch.Size([1, 3])
tensor([2., 2., 2.]) torch.Size([3])
tensor([3., 3.])
tensor([[0, 1, 2],
        [3, 4, 5]])
tensor([[ 0,  1,  3],
        [ 3,  7, 12]])

Process finished with exit code 0



4. 比较

import torch as t

a=t.linspace(0,15,6).view(2,3)
print(a)

b=t.linspace(15,0,6).view(2,3)
print(b)

print(a>b)

print(a[a>b])

print(t.max(a),a.dtype)

# dim=1 除去列，返回第一、二行最大值，索引为元素在第一第二行位置
print(t.max(a,dim=1))
print(t.max(b,dim=1))
print(t.max(a,dim=0))
print(t.max(b,dim=0))

print(t.max(a,b))

print(t.clamp(a,min=10))

print()



/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[ 0.,  3.,  6.],
        [ 9., 12., 15.]])
tensor([[15., 12.,  9.],
        [ 6.,  3.,  0.]])
tensor([[False, False, False],
        [ True,  True,  True]])
tensor([ 9., 12., 15.])
tensor(15.) torch.float32
torch.return_types.max(
values=tensor([ 6., 15.]),
indices=tensor([2, 2]))
torch.return_types.max(
values=tensor([15.,  6.]),
indices=tensor([0, 0]))
torch.return_types.max(
values=tensor([ 9., 12., 15.]),
indices=tensor([1, 1, 1]))
torch.return_types.max(
values=tensor([15., 12.,  9.]),
indices=tensor([0, 0, 0]))
tensor([[15., 12.,  9.],
        [ 9., 12., 15.]])
tensor([[10., 10., 10.],
        [10., 12., 15.]])


Process finished with exit code 0



5. 线性代数

import torch as t

a=t.Tensor(3,4)
print(a)
b=a.t()
print(b.is_contiguous())
b=b.contiguous()
print(b.is_contiguous())
print(b)


/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[4.8019e+30, 2.0700e-19, 2.6793e+20, 4.7420e+30],
        [2.3745e+23, 3.0357e+32, 6.7716e+22, 7.5554e+28],
        [1.8320e+25, 1.1723e-19, 5.0746e+31, 4.6114e+24]])
False
True
tensor([[4.8019e+30, 2.3745e+23, 1.8320e+25],
        [2.0700e-19, 3.0357e+32, 1.1723e-19],
        [2.6793e+20, 6.7716e+22, 5.0746e+31],
        [4.7420e+30, 7.5554e+28, 4.6114e+24]])

Process finished with exit code 0




6. Tensor  和 Numpy


import torch as t
import numpy as np

# auto 广播
a=t.ones(3,2)
b=t.zeros(2,3,1)
print(a+b)

# 等价

# 手动 广播
print(a.unsqueeze(0).expand(2,3,2)+b.expand(2,3,2))


a=t.ones([3,2],dtype=t.int)
print(a)

# numpy 默认类型 float64  tensor 默认类型是 float32
a=np.ones([2,3],dtype=np.float32)
print(a,a.dtype)

b=t.from_numpy(a)
print(b,b.dtype)

# 若Numpy类型不是Float32会新建b
b=t.Tensor(a)
print(b,b.dtype)

a[0,1]=100
print(b,b.dtype)

c=b.numpy()
print(c,c.dtype)

a=t.from_numpy(a)
a=a.T
print(a.size(),a.shape,a.dtype)
# expand 不会占用额外空间，只会在需要时才扩充，节省内存 
e=a.unsqueeze(0).expand(1000000000,3,2)
print(e.size(),e.shape)
e=e.numpy()
print(e.dtype,e.size)







/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[[1., 1.],
         [1., 1.],
         [1., 1.]],

        [[1., 1.],
         [1., 1.],
         [1., 1.]]])
tensor([[[1., 1.],
         [1., 1.],
         [1., 1.]],

        [[1., 1.],
         [1., 1.],
         [1., 1.]]])
tensor([[1, 1],
        [1, 1],
        [1, 1]], dtype=torch.int32)
[[1. 1. 1.]
 [1. 1. 1.]] float32
tensor([[1., 1., 1.],
        [1., 1., 1.]]) torch.float32
tensor([[1., 1., 1.],
        [1., 1., 1.]]) torch.float32
tensor([[  1., 100.,   1.],
        [  1.,   1.,   1.]]) torch.float32
[[  1. 100.   1.]
 [  1.   1.   1.]] float32
torch.Size([3, 2]) torch.Size([3, 2]) torch.float32
torch.Size([1000000000, 3, 2]) torch.Size([1000000000, 3, 2])
float32 6000000000

Process finished with exit code 0




