import torch as t
from torch import nn
from torch.autograd import Variable as V
import torch.nn.functional as F

class ResidualBlock(nn.Module):
    '''
    实现子module： Residual Block
    '''

    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):
        super(ResidualBlock, self).__init__()
        self.left = nn.Sequential(
            nn.Conv2d(inchannel, outchannel, 3, stride, 1, bias=False),
            nn.BatchNorm2d(outchannel),
            nn.ReLU(inplace=True),
            nn.Conv2d(outchannel, outchannel, 3, 1, 1, bias=False),
            nn.BatchNorm2d(outchannel)
        )
        self.right=shortcut

    def forward(self, x):
        out = self.left(x)
        residual = x if self.right is None else self.right(x)
        out += residual
        return F.relu(out)


class ResNet(nn.Module):
    '''
    实现主module：ResNet34
    ResNet包含多个layer，每个layer又包含多个residual block
    用子 module 实现 residual block，用 _make_layer函数实现layer
    '''

    def __init__(self, num_classes=1000):
        super(ResNet, self).__init__()
        self.pre = nn.Sequential(
           nn.Conv2d(3, 64, 7, 2, 3, bias=False),
           nn.BatchNorm2d(64),
           nn.ReLU(inplace=True),
           nn.MaxPool2d(3, 2, 1)
        )
        # 重复的layer,分别有3，4，6，3个residual block
        self.layer1 = self._make_layer(64, 128, 3)
        self.layer2 = self._make_layer(128, 256, 4, stride=2)
        self.layer3 = self._make_layer(256, 512, 6, stride=2)
        self.layer4 = self._make_layer(512, 512, 3, stride=2)
        # 分类用的全连接
        self.fc=nn.Linear(512,num_classes)

    def _make_layer(self,inchannel,outchannel,block_num,stride=1):
        '''

        构建layer，包含多个 residual block

        '''
        shortcut=nn.Sequential(
            nn.Conv2d(inchannel,outchannel,1,stride,bias=False),
            nn.BatchNorm2d(outchannel)
        )

        layers=[]
        layers.append(ResidualBlock(inchannel,outchannel,stride,shortcut))

        for i in range(1,block_num):
            layers.append(ResidualBlock(outchannel,outchannel))
        return nn.Sequential(*layers)

    def forward(self,x):
        x=self.pre(x)

        x=self.layer1(x)
        x=self.layer2(x)
        x=self.layer3(x)
        x=self.layer4(x)

        x=F.avg_pool2d(x,7)
        print("x.size(0)= ",x.size(0))
        x=x.view(x.size(0),-1)
        return self.fc(x)

model=ResNet()
input=t.autograd.Variable(t.randn(1,3,224,224))
o=model(input)
print(o)
print(o.shape)






/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
x.size(0)=  1
tensor([[-4.5748e-01, -6.8217e-01, -8.1485e-02,  4.1728e-01, -1.1034e-02,
         -3.5241e-01,  9.3442e-01, -5.1117e-01, -5.2769e-01,  2.9300e-01,
          3.0051e-02, -5.0377e-01, -5.6509e-01,  7.4168e-01,  8.4855e-02,
          1.8214e+00, -9.8998e-02, -4.4297e-01,  4.6124e-01,  4.2489e-01,
          7.5488e-02,  4.0012e-01, -6.8181e-01, -3.5106e-01, -6.2555e-01,
         -5.5021e-01, -1.0576e-01,  7.3522e-01, -6.3336e-01,  3.3863e-02,
         -1.5043e+00, -5.5993e-01, -5.3015e-01, -4.6708e-01, -6.0281e-03,
          2.4492e-01, -2.5583e-01,  6.0356e-02, -4.6262e-01, -1.2910e+00,
         -5.6129e-01, -5.7947e-01,  6.5105e-01, -7.5840e-01,  1.2795e-01,
         -6.6486e-01,  1.1862e+00, -1.0361e+00, -1.1668e+00, -5.4978e-01,
          1.0491e-01, -5.2811e-01,  6.6817e-01, -1.1777e-01, -3.2343e-01,
          7.0154e-01, -5.5636e-02, -1.9087e-01,  9.2315e-01, -1.4738e-01,
          7.8643e-01, -3.6009e-01, -1.1656e+00,  1.0182e+00,  8.3848e-01,
         -7.3201e-01, -4.2264e-01, -4.6564e-01,  4.0792e-01,  6.5151e-01,
          1.8994e-01, -2.7352e-01, -5.9866e-01, -4.2277e-01, -3.0233e-01,
          2.6124e-01,  8.0424e-01,  3.0851e-01, -6.6344e-01, -1.0594e-01,
          1.3072e-01,  9.4632e-01, -1.6147e-01, -1.3828e-01,  7.1057e-01,
          6.3626e-01, -1.0917e-01, -4.2516e-01, -3.1443e-01, -4.3657e-01,
          1.0732e+00,  5.9906e-01,  4.0313e-01,  1.0359e-01, -8.0054e-01,
         -1.0164e+00,  2.0731e-01,  3.2162e-01,  3.1281e-01,  8.5939e-02,
         -2.4309e-01, -4.6966e-01,  1.1839e+00, -9.3955e-01, -3.1175e-01,
          6.3203e-01, -2.8643e-01, -2.4866e-01, -3.0075e-01, -4.7445e-01,
         -9.8102e-02,  1.5136e-01, -6.9805e-01,  9.8535e-01, -3.0782e-01,
          4.3148e-01,  2.7997e-01, -2.8216e-01, -3.6275e-01, -1.4008e+00,
          2.7075e-01,  2.0166e-01,  4.8887e-01, -5.9424e-01, -2.4016e-01,
          2.8881e-01,  2.0516e-01, -4.7926e-01,  1.5841e-01, -5.8886e-01,
          3.3820e-01,  1.6482e+00,  5.1976e-01,  9.6055e-01,  1.1773e+00,
         -6.6525e-01, -1.7853e-01, -6.0398e-01,  3.2114e-01,  1.4934e-01,
         -1.3337e-01,  2.1185e-01, -1.0248e+00,  6.0433e-01,  7.5218e-01,
         -6.1016e-02, -7.1285e-01, -1.2881e-01, -8.0349e-01, -7.2894e-02,
          8.2934e-01, -4.4488e-01, -2.7651e-01,  1.0319e+00, -1.6604e-01,
          7.3528e-01,  1.1276e+00, -2.6527e-01, -4.4840e-03, -3.7159e-02,
          8.9711e-01, -7.0038e-03,  4.5410e-01,  1.7394e-01, -1.4441e-01,
          1.4731e+00,  1.2087e+00, -9.2113e-01, -4.1332e-01, -2.9027e-01,
          8.2645e-01,  6.3450e-01, -1.2988e-02,  4.3021e-01,  1.1928e+00,
          5.5424e-01, -3.5486e-01,  6.9371e-01, -3.1405e-01, -2.4367e-01,
          3.2358e-01, -2.5399e-01, -2.4063e-01, -9.0657e-02,  8.0715e-01,
          2.8977e-01, -6.1148e-01, -3.7352e-01, -3.7628e-01, -8.3810e-01,
          8.1902e-02,  1.2244e+00, -5.7938e-01, -2.9693e-01,  1.2049e+00,
         -7.4673e-02, -1.8054e+00,  7.0306e-01, -1.6381e-01, -7.7327e-01,
          3.7739e-01,  6.6606e-01, -5.2745e-01,  2.9015e-01, -3.9766e-01,
          4.9045e-01,  3.9206e-01, -5.8868e-02,  3.8112e-01,  1.4428e-01,
         -5.9182e-02,  4.7669e-01, -1.3598e+00, -9.4575e-02,  1.3974e+00,
         -8.6103e-01,  6.3111e-01, -2.1737e-01, -4.0633e-01, -2.5464e-01,
          4.9064e-01, -2.0884e-01,  5.8837e-01,  9.1267e-01, -5.8162e-01,
         -5.4420e-01, -1.4711e+00, -1.8120e-01, -6.2855e-01,  2.8364e-01,
         -6.8993e-01, -5.7022e-01,  8.2126e-01,  5.1213e-01,  8.1177e-01,
          6.3331e-01, -1.2213e+00,  4.3342e-01,  2.7006e-01,  3.3248e-01,
          1.4125e+00, -8.4508e-01,  1.3118e-01,  5.0679e-02,  6.4376e-02,
          1.0017e+00,  7.2271e-01, -3.7994e-01, -2.7459e-01,  5.7973e-01,
          1.5701e-01,  8.3836e-01,  7.4757e-02, -5.8578e-01, -5.9021e-01,
          4.1078e-01,  3.1788e-01,  9.7218e-01,  3.5057e-01,  2.7606e-01,
          2.0611e-01, -4.2464e-02, -1.3071e-01,  9.6819e-01, -2.2936e-01,
         -4.2245e-01, -2.4283e-01, -1.4527e-01, -2.9681e-01, -2.8853e-01,
          1.6496e-01,  1.3774e-01, -9.0961e-02, -1.8301e-01, -1.4839e+00,
          4.4506e-01,  1.6795e-01,  5.9358e-01, -3.0842e-01,  8.8679e-02,
          2.2521e-01,  6.3923e-01, -3.5995e-01,  1.4312e+00, -6.6065e-01,
         -1.8857e-04,  7.4243e-01, -1.3529e+00,  1.7652e-01,  3.6634e-01,
          5.6111e-01, -3.1263e-01, -6.1437e-01,  1.0666e+00, -2.5150e-01,
          2.4334e-01,  7.1192e-01, -4.4715e-01,  2.3248e-01, -5.8350e-01,
         -6.7179e-01,  2.7108e-01,  1.2108e+00, -4.0047e-01,  7.9191e-01,
         -2.4728e-01,  1.3280e-01,  6.4208e-01,  2.8744e-01, -8.2657e-01,
         -3.3477e-01,  3.0834e-01,  3.0268e-01, -1.8682e-02, -7.8027e-01,
          7.7951e-01,  2.1214e-01,  3.5771e-01, -1.7869e-01, -8.1145e-01,
         -3.4105e-02,  2.3332e-01,  5.2422e-02, -1.4969e+00, -5.9104e-01,
         -1.4311e-01,  9.1854e-01,  2.7195e-01,  8.9085e-02,  2.0390e-01,
          2.6884e-01,  7.2229e-01,  1.8969e-01,  1.1828e+00,  3.3589e-01,
          5.6692e-01, -7.0179e-02, -3.2997e-01,  6.6258e-01,  1.4462e-01,
          6.1455e-01, -4.5303e-01, -1.9461e-01, -6.6202e-01, -1.1681e+00,
         -2.1576e-01,  1.3536e-02, -2.9162e-01, -5.7780e-01, -1.5025e-01,
          6.4326e-01, -3.2057e-01, -1.0998e+00,  3.8547e-01, -7.6940e-01,
          4.1507e-02,  7.0507e-01, -1.5147e-01, -1.9430e-02, -6.3466e-02,
          7.5092e-02,  6.6608e-02,  4.3271e-01, -5.4840e-01,  4.4344e-01,
         -2.8944e-01,  2.5283e-01, -4.0575e-01, -3.1507e-01, -5.1686e-01,
         -6.9473e-01, -7.2408e-01,  4.0238e-01, -2.5442e-01, -7.8417e-01,
          1.4725e+00, -1.0587e-01,  4.4957e-01,  9.0528e-01, -4.4295e-01,
          3.5122e-02, -8.7168e-01, -7.0980e-02,  6.8464e-01, -3.4545e-01,
         -6.1594e-01, -2.2165e-01,  1.3820e+00,  1.6991e-01, -3.5506e-01,
          5.4632e-01, -3.3565e-01, -2.6959e-01,  5.1375e-01,  8.1778e-01,
          2.9808e-01,  4.0371e-01, -6.5462e-02, -4.2593e-01,  2.4209e-01,
         -3.0714e-01, -1.0436e-02,  4.1612e-01,  3.5157e-02, -1.0167e+00,
          4.5416e-01,  8.1489e-02,  6.6547e-01, -2.2010e-01, -2.4744e-01,
          1.1281e-01, -7.7244e-04, -4.7719e-01, -5.6664e-01,  6.2695e-01,
         -1.5546e+00,  5.3551e-01,  1.1668e-02, -8.2529e-01,  3.0338e-01,
          1.5867e-02, -5.6961e-01,  9.8610e-01, -2.1179e-01,  4.7780e-01,
          3.4288e-01, -1.5148e-01,  6.1167e-01,  1.0678e-01,  3.2201e-01,
          1.3672e-01, -3.4978e-01,  5.2542e-01, -6.6368e-01,  8.2010e-01,
          2.8223e-01, -1.2550e+00, -2.8830e-02, -1.2117e+00,  1.0786e-01,
         -2.0530e-01,  2.3462e-01, -1.6840e-01,  5.9364e-01, -3.0810e-01,
          9.4740e-03, -8.1472e-01, -3.2880e-01, -3.7667e-01, -1.6901e+00,
          6.5170e-01, -2.0458e-02, -3.3681e-01,  6.9528e-01,  1.9034e-01,
          5.9037e-02,  1.8274e-01, -8.4263e-01,  4.8973e-01,  1.0922e+00,
         -2.4792e-01, -3.1897e-01, -9.8138e-01, -8.7536e-01, -1.3588e-01,
         -5.2335e-01, -5.1494e-01,  7.6645e-01, -8.8247e-03,  5.3827e-01,
          6.7704e-01, -1.4929e-01, -1.7771e-02,  1.4038e-01,  5.2576e-01,
         -5.5610e-01, -5.0455e-01,  6.8087e-01,  7.9805e-01, -2.8552e-01,
         -6.1206e-02,  2.4153e-01,  1.8983e-01, -3.8795e-01,  5.1917e-02,
         -1.5466e-01, -1.8002e-01, -1.4593e-01, -5.2324e-01,  3.8402e-01,
         -3.7483e-01, -1.3350e+00,  6.6225e-01,  8.4999e-01,  3.0467e-01,
         -5.9499e-01,  1.4117e+00,  8.0853e-02, -1.8283e+00, -5.2532e-01,
         -7.7287e-01,  1.0137e+00,  5.3791e-01, -7.6675e-01,  1.1130e-01,
          1.1229e+00,  1.4736e-01,  9.7537e-01,  5.7755e-01, -8.0534e-02,
          7.0479e-01, -3.2753e-01,  6.0529e-01, -4.6138e-02,  1.0104e-01,
          4.1475e-01, -9.0180e-01,  5.6650e-02,  3.7101e-01,  4.5133e-01,
         -5.0166e-01,  8.0271e-01, -5.0872e-01,  6.0875e-01, -8.8268e-01,
         -3.6293e-01, -1.0604e+00,  3.7120e-01,  9.1927e-01,  1.0609e-01,
         -3.6565e-01, -4.3543e-01, -4.2142e-02, -1.1649e+00, -4.4933e-01,
         -9.2946e-02, -1.0466e-01,  3.1773e-01, -8.0478e-02,  6.0541e-01,
          4.5111e-01,  1.7332e-01, -7.2217e-01,  1.1464e+00, -6.2029e-01,
         -1.6231e-01,  8.6412e-01,  2.7185e-01, -4.7005e-01,  7.0813e-01,
         -8.3315e-01,  4.1485e-01, -3.2016e-02,  1.2424e+00,  8.5320e-01,
          4.5182e-01, -2.0875e-01,  2.4878e-01,  5.3322e-02,  9.7709e-01,
          8.2507e-01, -1.3334e-02,  4.8930e-01,  4.2055e-01, -1.6183e-01,
         -9.5836e-01,  8.3249e-02, -2.1990e-01,  8.5506e-01, -7.2288e-01,
         -2.9579e-01,  1.2484e-02, -5.0825e-01, -8.7914e-01, -9.6441e-01,
          1.9075e-01, -1.1227e+00,  3.7103e-01,  1.0992e+00,  1.4629e-01,
         -2.9865e-01, -3.1036e-01,  9.0742e-01, -6.5361e-01,  8.9128e-01,
          8.6868e-01, -4.6107e-01, -3.2739e-01, -3.6907e-01, -9.6680e-01,
          1.2572e-01,  1.5205e-01,  1.7158e-01,  4.3109e-01,  1.0847e+00,
         -8.6984e-01,  7.0143e-01, -1.8764e-01,  8.9011e-01,  8.6802e-01,
         -1.8686e-01,  4.0387e-02,  6.3855e-01, -3.0352e-01, -7.7400e-02,
         -2.2685e-01, -2.6736e-01,  6.7931e-01, -1.2424e+00,  4.7851e-01,
          1.4948e-01, -4.6973e-01,  6.4008e-01, -3.8949e-01,  2.4342e-01,
         -8.7911e-01, -6.0215e-01,  2.0350e-01,  5.4401e-02,  9.9344e-02,
          9.3843e-03,  6.7040e-01, -5.1440e-01,  3.2173e-01,  3.0923e-01,
          9.3862e-01,  1.8196e-01, -1.7169e+00, -5.9142e-02, -1.8847e-01,
          7.4896e-01,  2.9326e-02,  9.1526e-01, -1.0519e+00,  8.4087e-01,
          6.2680e-01,  5.9319e-01,  2.6654e-02, -1.8950e-01, -7.0424e-02,
         -2.2136e-01, -1.6179e-01,  2.7219e-01, -4.4352e-01, -2.2757e-03,
          1.0752e+00,  4.4814e-01, -4.0991e-01,  5.0595e-01, -1.0441e+00,
          1.5092e-01,  2.4005e-01, -1.1587e+00, -1.8976e-02, -2.0491e-01,
         -7.8768e-01, -1.0514e-01, -4.5463e-01, -2.1651e-01,  6.2493e-01,
          4.4786e-01,  4.2465e-01,  2.8925e-01, -8.3154e-02,  4.3100e-01,
         -2.1331e-01, -3.9779e-01,  2.3755e-01, -4.2662e-01,  1.1817e-01,
          7.1058e-01,  1.6290e+00,  1.1152e-01,  1.2361e+00,  4.8097e-01,
          9.5573e-01,  4.9367e-01, -4.0071e-01, -1.5634e-01,  8.0044e-01,
          6.4010e-01, -6.7701e-01,  4.9523e-01,  1.1542e-01,  3.0141e-01,
          5.7912e-02,  7.0384e-01, -2.4871e-01, -7.6014e-01,  4.9813e-01,
          5.4494e-01, -1.1535e-01,  7.6025e-01,  3.2742e-01,  2.8159e-01,
         -7.5622e-01, -1.0261e-01,  1.1806e-01,  6.5976e-01,  2.7955e-01,
          3.8356e-01, -2.5126e-01,  3.3761e-01,  9.0330e-01, -2.6524e-01,
          6.4387e-01,  3.8499e-01, -3.2477e-01, -1.8890e-01,  5.9303e-01,
         -2.2207e-01, -1.0016e-01,  6.6406e-01, -1.5783e-01,  2.3746e-01,
         -4.6403e-01, -1.8035e-01,  1.2187e-01, -5.3447e-01,  6.2470e-01,
          1.6835e-01, -3.2580e-01,  5.7816e-01,  6.2277e-01, -1.7742e-01,
         -5.4150e-01, -9.3010e-01,  6.3311e-01, -9.8165e-01, -3.7235e-01,
          7.9188e-01,  7.0218e-01, -3.7730e-01, -7.1023e-02,  9.2626e-01,
          5.7702e-01, -1.0649e+00, -1.2203e-01, -3.0055e-01,  2.9164e-01,
          5.7535e-01,  1.5070e+00,  2.3993e-02,  5.1806e-01, -4.7329e-01,
          4.1533e-01, -2.6498e-01, -4.2629e-02, -8.9726e-01,  3.7208e-01,
         -7.5039e-01, -4.1678e-02,  8.1922e-02, -7.0452e-01, -1.6585e+00,
          9.8939e-01, -5.2102e-01, -3.6625e-01,  2.7160e-01,  7.2185e-01,
         -4.3516e-01, -8.7550e-01, -6.1421e-01,  7.8203e-01,  4.1752e-01,
         -7.6485e-02,  5.4312e-01,  7.3279e-02,  5.8464e-01, -1.1544e-01,
          1.8595e-02,  1.1089e+00, -4.9816e-01, -6.4005e-01, -7.4390e-01,
          3.6897e-02,  2.4098e-01, -1.5755e-01, -8.2328e-01,  1.4994e-01,
         -7.3402e-01,  4.1690e-01,  8.4312e-01, -3.7098e-02, -1.1309e+00,
          6.8768e-01,  5.8817e-01, -4.5508e-02,  3.2939e-01, -5.4431e-01,
         -7.4911e-01,  4.9329e-01,  3.2730e-01, -3.3571e-01,  4.5137e-01,
         -8.4758e-01,  6.3976e-01,  9.0408e-01, -3.4576e-02, -5.6242e-01,
          1.8061e-01,  6.3193e-01, -3.3419e-01,  4.9598e-01,  1.0236e-01,
         -3.7802e-02,  3.8353e-01, -7.3435e-01,  1.6905e-01,  9.9437e-01,
         -1.1181e+00,  3.1229e-01, -2.6140e-02,  6.1801e-01,  6.1725e-01,
         -4.0112e-01,  6.1801e-01, -2.6705e-01,  4.4922e-01,  8.8123e-02,
          2.9213e-02,  2.6200e-01, -3.5769e-01, -7.3347e-01, -6.7786e-01,
         -9.6206e-01,  1.8808e-01, -1.0435e+00, -3.2714e-01, -3.6142e-01,
          6.9669e-01,  8.7786e-01, -1.5581e-01, -3.6966e-01, -7.6344e-01,
         -3.3471e-01,  3.3903e-01, -8.3808e-02, -7.2895e-02,  1.3301e+00,
          1.8108e+00, -7.5169e-03,  6.6448e-01, -4.1004e-01,  3.4766e-01,
          5.5889e-01,  1.0205e+00, -5.2704e-01, -3.5643e-01, -3.9620e-01,
         -4.9650e-01, -5.8038e-01,  3.5013e-01, -1.0521e+00, -2.3907e-01,
          7.9097e-01,  2.3548e-01,  2.5637e-01,  1.1325e+00, -2.3533e-01,
         -3.1883e-01,  7.6601e-01,  3.7568e-01,  4.5283e-01,  3.1146e-02,
         -4.8508e-01,  8.2491e-01,  7.4303e-01,  3.7879e-01, -7.4032e-01,
         -6.5054e-03,  7.9428e-02, -5.7804e-01, -6.6215e-02, -4.1559e-01,
          4.7991e-01, -2.7768e-01, -6.7285e-01, -6.7731e-01, -3.6877e-01,
          5.5791e-01,  6.8056e-01,  2.0969e-01, -2.0761e-02,  1.6629e-01,
          7.0812e-01,  3.6114e-01,  7.5282e-01, -2.4876e-01,  3.4029e-01,
          6.4288e-01,  7.1443e-02, -5.2543e-01, -3.6801e-01,  5.8622e-01,
         -2.3172e-01, -2.3521e-01,  1.8054e-01,  2.0769e-01,  8.0141e-01,
         -4.4392e-01, -2.4280e-01, -2.4672e-01,  7.8019e-01,  4.0931e-02,
         -9.6452e-01,  9.1766e-01,  3.6343e-01, -6.8788e-01, -1.4708e+00,
          4.7128e-01, -6.6860e-01, -1.7728e-01,  1.0998e+00, -3.2288e-01,
          6.5489e-01,  7.4950e-01, -5.4142e-01,  1.2089e+00, -1.7524e-01,
         -1.0844e+00,  4.9685e-02,  6.6262e-01, -4.8182e-01, -1.0806e-01,
         -1.1614e-01, -2.8223e-01,  1.3852e-01, -1.4636e-01,  2.9779e-01,
          7.6079e-01, -3.0432e-01, -1.0069e-01, -2.6246e-01, -2.7970e-02,
         -1.4161e+00,  3.6804e-01, -1.2553e-01,  6.9213e-01, -4.4558e-01,
         -9.2952e-01, -7.8372e-01, -1.2690e+00,  9.6381e-01,  6.7682e-01,
         -5.2295e-01, -3.5885e-01, -7.8194e-01,  3.3073e-02,  5.0837e-01,
         -6.8310e-01, -3.7191e-01,  1.8697e-01, -1.7556e-01, -5.1632e-01,
         -4.8808e-01,  5.8978e-01,  1.2627e+00,  1.2669e-02,  4.3332e-01,
         -6.0027e-01,  5.4878e-01,  3.6715e-01, -9.4729e-01,  3.7966e-01,
          8.5362e-01, -7.6174e-04,  3.5910e-01, -7.5290e-02,  1.6599e-01,
          2.2369e-01,  6.1244e-01, -5.7440e-01,  2.0268e-02,  1.3614e+00,
         -1.0978e+00, -3.2880e-01, -9.4595e-01, -1.0299e+00, -8.2938e-01,
          2.3901e-01, -1.1064e-01,  5.8256e-02, -1.3251e-02, -3.4240e-01,
         -7.5419e-02, -2.1935e-01, -6.4202e-02,  6.3958e-01,  8.4248e-02,
         -3.6717e-01,  1.4352e-01, -6.1233e-01, -3.7284e-01,  7.2639e-01,
         -7.6803e-01,  7.0611e-01,  5.2336e-01, -5.5170e-01,  1.4327e-01]],
       grad_fn=<AddmmBackward>)
torch.Size([1, 1000])

Process finished with exit code 0









当然，与 Pytorch 配套的图像工具包torchvision 易经实现了深度学习中大多数经典的模型，
其中就包括 ResNet34，可以通过以下代码使用：

from torchvision import models
import torch as t
model = models.resnet34()
o=model(t.randn(3,3,3,3))
print(o,o.shape)


/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
tensor([[-1.0203, -0.1896, -0.3845,  ..., -0.1285,  1.0731, -0.4883],
        [-2.4063,  0.3272,  0.5353,  ..., -0.9063,  0.4161,  0.9797],
        [-0.8344, -0.2085,  0.5996,  ..., -0.3980,  0.0147,  1.3197]],
       grad_fn=<AddmmBackward>) torch.Size([3, 1000])

Process finished with exit code 0

