

import matplotlib.pyplot as plt
import torchvision as tv
import torch as t
# import torchvision.transforms as transforms
#  error
from torchvision import transforms
from torchvision.transforms import ToPILImage

import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable

# 定义优化器
from torch import optim

# time
import time

# define data pre-solve
show = ToPILImage()  # Tensor -> Image
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

# train dataset
trainset = tv.datasets.CIFAR10(
    root='/media/wangbin/F/',
    train=True,
    download=True,
    transform=transform
)
trainloader = t.utils.data.DataLoader(
    trainset,
    batch_size=5,
    shuffle=True,
    num_workers=2
)

# teset set
testset = tv.datasets.CIFAR10(
    '/media/wangbin/F',
    train=False,
    download=True,
    transform=transform
)

testloader = t.utils.data.DataLoader(
    testset,
    batch_size=5,
    shuffle=False,
    num_workers=2
)
classes = ('plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck')


# dataiter = iter(trainloader)
# images, labels = dataiter.next()


# print(' '.join('%11s' % classes[labels[j]] for j in range(4)))
# for j in range(0, 4):
#     plt.imshow(show((images[j] + 1) / 2).resize((100, 100)))
#     plt.show()


class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))
        x = F.max_pool2d(F.relu(self.conv2(x)), 2)
        x = x.view(x.size()[0], -1)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x


net = Net()
print(net)

# 定义交叉熵损失(损失函数)和优化器   loss 和 optimizer
criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

start = time.time()


# # CPU trainset 训练网络
# for epoch in range(2):
#     running_loss = 0.0
#     for i, data in enumerate(trainloader, 0):
#         # 输入数据
#         inputs, labels = data
#         inputs, labels = Variable(inputs), Variable(labels)
#         # 梯度清零
#         optimizer.zero_grad()
#         # forward+backward
#         outputs = net(inputs)
#         loss = criterion(outputs, labels)
#
#         loss.backward()
#         # 更新参数
#         optimizer.step()
#         # 打印log信息
#         # print(loss.data,running_loss,loss.data+running_loss)
#         # print(loss.data)
#         running_loss += loss.data
#         if i % 2000 == 1999:
#             print('[%d , %5d] loss %.3f' % (epoch + 1, i + 1, running_loss / 2000))
#             running_loss = 0.0

# GPU trainset
for epoch in range(2):
    running_loss = 0.0
    for i, data in enumerate(trainloader, 0):
        # 输入数据
        inputs, labels = data
        inputs, labels = Variable(inputs), Variable(labels)
        net.cuda()
        # 梯度清零
        optimizer.zero_grad()
        # forward+backward

        # if t.cuda.is_available():
        # net.cuda()
        inputs = inputs.cuda()
        labels = labels.cuda()
        output = net(Variable(inputs))
        # outputs = net(inputs)
        loss = criterion(output, labels)

        loss.backward()
        # 更新参数
        optimizer.step()
        # 打印log信息
        # print(loss.data,running_loss,loss.data+running_loss)
        # print(loss.data)
        running_loss += loss.data
        if i % 2000 == 1999:
            print('[%d , %5d] loss %.3f' % (epoch + 1, i + 1, running_loss / 2000))
            running_loss = 0.0
#
# print('Finished Training')
# end = time.time()
# print((end - start))

# # 实际的labels
# dataiter = iter(testloader)
# images, labels = dataiter.next()
# print('实际的label：', ' '.join('%08s' % classes[labels[j]] for j in range(4)))
# for j in range(4):
#     plt.imshow(show((images[j] + 1) / 2).resize((100, 100)))
#     plt.show()

# # net计算的labels
# outputs = net(Variable(images))
# _, predicted = t.max(outputs.data, 1)
# print('预测结果：', "*".join("%s" % classes[predicted[j]] for j in range(4)))


# # CPU  testset
# start1 = time.time()
# correct = 0
# total = 0
# for data in testloader:
#     images, labels = data
#     outputs = net(Variable(images))
#     _, predicted = t.max(outputs.data, 1)
#     total += labels.size(0)
#     correct += (predicted == labels).sum()
# print("10000张测试集中的准确率为：%d %%" % (100 * correct / total))
# end1 = time.time()
# print(end1 - start1)


#  GPU testset
start2 = time.time()
correct = 0
total = 0
for data in testloader:
    images, labels = data
    if t.cuda.is_available():
        net.cuda()
        images = images.cuda()
        labels = labels.cuda()
        output = net(Variable(images))
        _, predicted = t.max(output.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum()
print("10000张测试集中的准确率为：%d %%" % (100 * correct / total))
end2 = time.time()
print(end2 - start2)





## 测试结果

/home/wangbin/anaconda3/envs/deep_learning/bin/python3.7 /home/wangbin/anaconda3/envs/deep_learning/project/main.py
Files already downloaded and verified
Files already downloaded and verified
Net(
  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=400, out_features=120, bias=True)
  (fc2): Linear(in_features=120, out_features=84, bias=True)
  (fc3): Linear(in_features=84, out_features=10, bias=True)
)
[1 ,  2000] loss 2.191
[1 ,  4000] loss 1.807
[1 ,  6000] loss 1.635
[1 ,  8000] loss 1.537
[1 , 10000] loss 1.464
[2 ,  2000] loss 1.426
[2 ,  4000] loss 1.378
[2 ,  6000] loss 1.358
[2 ,  8000] loss 1.293
[2 , 10000] loss 1.279
10000张测试集中的准确率为：55 %
2.6315536499023438

Process finished with exit code 0
